# -*- coding: utf-8 -*-
"""trabalho_celulas_FelipeBaglioli.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1IhQE7a9Hytv64i2uYqjLQw_4Wgy_o0rd
"""

import torch
from torch import nn
import requests
import zipfile
from pathlib import Path
from torch.utils.data import DataLoader
from torchvision import datasets
from torchvision.transforms import v2
import random
from PIL import Image
import matplotlib.pyplot as plt
import shutil
import os
from timeit import default_timer as timer
from typing import Tuple, Dict, List

# Deixar o codigo independente de dispositivo:

device = 'cuda' if torch.cuda.is_available() else 'cpu'
device

# Criar as pastas com os arquivos

dataPath = Path('data/')

imgPath = dataPath / 'cells_blue_pink'

if imgPath.is_dir():
  pass
else:
  imgPath.mkdir(parents = True, exist_ok = True)

# Fazer o Download

url = 'https://github.com/emiliomercuri/ciencia_dados/raw/main/dados/cells_blue_pink.zip'

with open(dataPath / 'cells_blue_pink.zip', 'wb') as f:

  req = requests.get(url)
  f.write(req.content)

# Extrair os arquivos

with zipfile.ZipFile(dataPath / 'cells_blue_pink.zip', 'r') as zipf:
  zipf.extractall(dataPath)

# Retirar um diretorio indesejado:

if (dataPath / '__MACOSX').is_dir():
  shutil.rmtree(dataPath / '__MACOSX')

print('Download de dados completo. Favor checar a pasta de dados.')

# Caminhos de teste e treinamento

train_dir = imgPath / 'train'
test_dir = imgPath / 'test'

# Padronizar tamanhos e gerar um tensor

std_size = v2.Compose([
    v2.ToImage(),
    v2.Resize(size = (224, 224), antialias = True),
    v2.ToDtype(torch.float32, scale=True)
])

# Transformacoes com data augmentation

std_size_aug = v2.Compose([
    v2.ToImage(),
    v2.Resize(size = (224, 224), antialias = True),
    v2.TrivialAugmentWide(num_magnitude_bins = 31),
    v2.ToDtype(torch.float32, scale=True)
])

def plot_transformed_images(image_paths: list, transform, n=3, seed=None):
  """
  Select random images from a path of images and loads/transforms
  them then plots the original vs the transformed version.
  """
  if seed:
    random.seed(seed)
  random_image_paths = random.sample(image_paths, k=n)
  for image_path in random_image_paths:
    with Image.open(image_path) as f:
      fig, ax = plt.subplots(nrows=1, ncols=2)
      ax[0].imshow(f)
      ax[0].set_title(f"Original\nSize: {f.size}")
      ax[0].axis(False)

      # Transform and plot target image
      transformed_image = transform(f).permute(1,2,0) # note we will need to change chape for matplotlib (C,H,W) -> (H,W,C)
      ax[1].imshow(transformed_image)
      ax[1].set_title(f"Transformed\nShape: {transformed_image.shape}")
      ax[1].axis("off")

      fig.suptitle(f"Class: {image_path.parent.stem}", fontsize=16)

# Transformacao sem Augmentation:

image_path_list = list(imgPath.glob("*/*/*.jpg"))

plot_transformed_images(image_paths=image_path_list,
                        transform=std_size,
                        n=3,
                        seed=42)

# Transformacao com Augmentation:

plot_transformed_images(image_paths=image_path_list,
                        transform=std_size_aug,
                        n=3,
                        seed=None)

# Carregar os datasets

aug = False # basta trocar para ter ou nao augmentation

if aug == True:

  train_data = datasets.ImageFolder(root = train_dir,
                                    transform = std_size_aug,
                                    target_transform = None)

  test_data = datasets.ImageFolder(root = test_dir,
                                   transform = std_size)  # Nao precisamos aumentar os dados de teste

else:

  train_data = datasets.ImageFolder(root = train_dir,
                                    transform = std_size,
                                    target_transform = None)

  test_data = datasets.ImageFolder(root = test_dir,
                                   transform = std_size)

train_data, test_data

# configurar os DataLoaders:

batch_sz = 1

train_dataloader = DataLoader(dataset = train_data,
                              batch_size = batch_sz,
                              num_workers = os.cpu_count(),
                              shuffle = True)

test_dataloader = DataLoader(dataset = test_data,
                             batch_size = batch_sz,
                             num_workers = os.cpu_count(),
                             shuffle = False)

class tinyVGG(nn.Module):

  def __init__(self, input_shape : int, hidden_units : int, output_shape : int) -> None:

    super().__init__()
    self.convBlock1 = nn.Sequential(
        nn.Conv2d(in_channels = input_shape,
                  out_channels = hidden_units,
                  kernel_size = 3,
                  stride = 1,
                  padding = 0),
        nn.ReLU(),
        nn.Conv2d(in_channels = hidden_units,
                  out_channels = hidden_units,
                  kernel_size = 3,
                  stride = 1,
                  padding = 0),
        nn.ReLU(),
        nn.MaxPool2d(kernel_size = 2, stride = 2)
    )

    self.convBlock2 = nn.Sequential(
        nn.Conv2d(in_channels = hidden_units,
                  out_channels = hidden_units,
                  kernel_size = 3,
                  stride = 1,
                  padding = 0),
        nn.ReLU(),
        nn.Conv2d(in_channels = hidden_units,
                  out_channels = hidden_units,
                  kernel_size = 3,
                  stride = 1,
                  padding = 0),
        nn.ReLU(),
        nn.MaxPool2d(kernel_size = 2, stride = 2)
    )

    self.classifier = nn.Sequential(
        nn.Flatten(),
        nn.Linear(in_features = hidden_units*53*53,
                  out_features = output_shape)
    )

  def forward(self, x : torch.Tensor):
    x = self.convBlock1(x)
    #print(x.shape)
    x = self.convBlock2(x)
    #print(x.shape)
    x = self.classifier(x)
    #print(x.shape)

    #return self.classifier(self.conv_block_2(self.conv_block_1(x)))
    return x

class AlexNet(nn.Module):

  def __init__(self, input_shape : int, hidden_units : int, output_shape : int) -> None:

    super().__init__()

    self.ConvLayer1 = nn.Sequential(
        nn.Conv2d(in_channels = input_shape,
                  out_channels = hidden_units,
                  kernel_size = 11,
                  stride = 4,
                  padding = 0),
        nn.BatchNorm2d(hidden_units),
        nn.ReLU(),
        nn.MaxPool2d(kernel_size = 3, stride = 2)
    )

    self.ConvLayer2 = nn.Sequential(
        nn.Conv2d(in_channels = hidden_units,
                  out_channels = hidden_units*3,
                  kernel_size = 5,
                  stride = 2,
                  padding = 2),
        nn.BatchNorm2d(hidden_units*3),
        nn.ReLU(),
        nn.MaxPool2d(kernel_size = 3, stride = 2)
    )

    self.ConvLayer3 = nn.Sequential(
        nn.Conv2d(in_channels = hidden_units*3,
                  out_channels = hidden_units*6,
                  kernel_size = 3,
                  stride = 1,
                  padding = 1),
        nn.BatchNorm2d(hidden_units*6),
        nn.ReLU()
    )

    self.ConvLayer4 = nn.Sequential(
        nn.Conv2d(in_channels = hidden_units*6,
                  out_channels = hidden_units*4,
                  kernel_size = 3,
                  stride = 1,
                  padding = 1),
        nn.BatchNorm2d(hidden_units*4),
        nn.ReLU()
    )

    self.ConvLayer5 = nn.Sequential(
        nn.Conv2d(in_channels = hidden_units*4,
                  out_channels = hidden_units*4,
                  kernel_size = 3,
                  stride = 1,
                  padding = 1),
        nn.BatchNorm2d(hidden_units*4),
        nn.ReLU(),
        nn.MaxPool2d(kernel_size = 3, stride = 2)
    )

    self.dropOut1 = nn.Sequential(
        nn.Dropout(p = 0.5, inplace = False),
        nn.Flatten(),
        nn.Linear(in_features = (hidden_units*4)*2*2, out_features = hidden_units, bias = True),
        nn.ReLU()
    )

    self.dropOut2 = nn.Sequential(
        nn.Dropout(p = 0.5, inplace = False),
        nn.Linear(in_features = hidden_units, out_features = hidden_units, bias = True),
        nn.ReLU()
    )

    self.classifier = nn.Sequential(
        nn.Linear(in_features = hidden_units, out_features = output_shape, bias = True))

  def forward(self, x):

      x = self.ConvLayer1(x)
      #print(x.shape)
      x = self.ConvLayer2(x)
      #print(x.shape)
      x = self.ConvLayer3(x)
      #print(x.shape)
      x = self.ConvLayer4(x)
      #print(x.shape)
      x = self.ConvLayer5(x)
      #print(x.shape)

      x = self.dropOut1(x)
      #print(x.shape)
      x = self.dropOut2(x)
      #print(x.shape)
      x = self.classifier(x)
      #print(x.shape)

      return x

torch.manual_seed(42)
torch.cuda.manual_seed(42)

model0 = tinyVGG(input_shape=3, # number of color channels (3 for RGB)
                 hidden_units=10,
                 output_shape=len(train_data.classes)).to(device)

torch.manual_seed(42)
torch.cuda.manual_seed(42)

model1 = AlexNet(input_shape = 3,
                 hidden_units = 64,
                 output_shape = len(train_data.classes)).to(device)

# Forward pass para definir o tamanho da camada no final:

img_batch, label_batch = next(iter(train_dataloader))
img_single, label_single = img_batch[0].unsqueeze(dim = 0), label_batch[0]
print(f'Formato da Imagem: {img_single.shape}\n')

model0.eval()
with torch.inference_mode():
    pred = model0(img_single.to(device))

print(f'Logits de saida:\n{pred}\n')
print(f'Porbabilidades das predicoes de saida:\n{torch.softmax(pred, dim=1)}\n')
print(f'Classe de saida predita:\n{torch.argmax(torch.softmax(pred, dim=1), dim=1)}\n')
print(f'Classe real:\n{label_single}')

def train_step(model: torch.nn.Module,
               dataloader : torch.utils.data.DataLoader,
               loss_fn : torch.nn.Module,
               optimizer : torch.optim.Optimizer,
               device = device):

  model.train()

  train_loss, train_acc = 0, 0

  for batch, (X, y) in enumerate(dataloader):

    X, y, = X.to(device), y.to(device)

    y_pred = model(X)

    loss = loss_fn(y_pred, y)
    train_loss += loss.item()

    opt.zero_grad()
    loss.backward()
    opt.step()

    y_pred_classes = torch.argmax(torch.softmax(y_pred, dim = 1), dim = 1)
    train_acc += (y_pred_classes == y).sum().item()/len(y_pred)

  train_loss /= len(dataloader)  # completando a media
  train_acc /= len(dataloader)

  return train_loss, train_acc

def test_step(model: torch.nn.Module,
              dataloader : torch.utils.data.DataLoader,
              loss_fn : torch.nn.Module,
              device = device):

  model.eval()

  test_loss, test_acc = 0, 0

  with torch.inference_mode():

    for batch, (X, y) in enumerate(dataloader):

      X, y, = X.to(device), y.to(device)

      test_preds = model(X)

      loss = loss_fn(test_preds, y)
      test_loss += loss.item()

      test_pred_classes = torch.argmax(torch.softmax(test_preds, dim = 1), dim = 1)
      test_acc += (test_pred_classes == y).sum().item()/len(test_preds)

  test_loss /= len(dataloader)  # completando a media
  test_acc /= len(dataloader)

  return test_loss, test_acc

from tqdm.auto import tqdm

# 1. Take in various parameters required for training and test steps
def train(model: torch.nn.Module,
          train_dataloader: torch.utils.data.DataLoader,
          test_dataloader: torch.utils.data.DataLoader,
          optimizer: torch.optim.Optimizer,
          loss_fn: torch.nn.Module = nn.CrossEntropyLoss(),
          epochs: int = 20):

    # 2. Create empty results dictionary
    results = {"train_loss": [],
        "train_acc": [],
        "test_loss": [],
        "test_acc": []
    }

    # 3. Loop through training and testing steps for a number of epochs
    for epoch in tqdm(range(epochs)):
        train_loss, train_acc = train_step(model=model,
                                           dataloader=train_dataloader,
                                           loss_fn=loss_fn,
                                           optimizer=optimizer)
        test_loss, test_acc = test_step(model=model,
                                        dataloader=test_dataloader,
                                        loss_fn=loss_fn)

        # 4. Print out what's happening
        print(
            f"Epoch: {epoch+1} | "
            f"train_loss: {train_loss:.4f} | "
            f"train_acc: {train_acc:.4f} | "
            f"test_loss: {test_loss:.4f} | "
            f"test_acc: {test_acc:.4f}"
        )

        # 5. Update results dictionary
        results["train_loss"].append(train_loss)
        results["train_acc"].append(train_acc)
        results["test_loss"].append(test_loss)
        results["test_acc"].append(test_acc)

    # 6. Return the filled results at the end of the epochs
    return results

# Modelo TinyVGG

torch.manual_seed(42)
torch.cuda.manual_seed(42)

epochs = 12

loss_fn = nn.CrossEntropyLoss()
opt = torch.optim.Adam(params = model0.parameters(), lr = .001)

start_time = timer()

model0_results = train(model = model0,
                       train_dataloader = train_dataloader,
                       test_dataloader = test_dataloader,
                       optimizer = opt,
                       loss_fn = loss_fn,
                       epochs = epochs)

end_time = timer()
print(f'Tempo total de treinamento: {end_time-start_time:.3f} s')

# Modelo AlexNet

torch.manual_seed(42)
torch.cuda.manual_seed(42)

epochs = 12

loss_fn = nn.CrossEntropyLoss()
opt = torch.optim.Adam(params = model1.parameters(), lr = .001)

start_time = timer()

model1_results = train(model = model1,
                       train_dataloader = train_dataloader,
                       test_dataloader = test_dataloader,
                       optimizer = opt,
                       loss_fn = loss_fn,
                       epochs = epochs)

end_time = timer()
print(f'Tempo total de treinamento: {end_time-start_time:.3f} s')

def plot_loss_curves(results: Dict[str, List[float]]):
    """Plots training curves of a results dictionary.

    Args:
        results (dict): dictionary containing list of values, e.g.
            {"train_loss": [...],
             "train_acc": [...],
             "test_loss": [...],
             "test_acc": [...]}
    """

    # Get the loss values of the results dictionary (training and test)
    loss = results['train_loss']
    test_loss = results['test_loss']

    # Get the accuracy values of the results dictionary (training and test)
    accuracy = results['train_acc']
    test_accuracy = results['test_acc']

    # Figure out how many epochs there were
    epochs = range(len(results['train_loss']))

    # Setup a plot
    plt.figure(figsize=(15, 7))

    # Plot loss
    plt.subplot(1, 2, 1)
    plt.plot(epochs, loss, label='train_loss')
    plt.plot(epochs, test_loss, label='test_loss')
    plt.title('Loss')
    plt.xlabel('Epochs')
    plt.legend()

    # Plot accuracy
    plt.subplot(1, 2, 2)
    plt.plot(epochs, accuracy, label='train_accuracy')
    plt.plot(epochs, test_accuracy, label='test_accuracy')
    plt.title('Accuracy')
    plt.xlabel('Epochs')
    plt.legend();

plot_loss_curves(model0_results)

plot_loss_curves(model1_results)

def make_predictions(model: torch.nn.Module,
                     data: list,
                     device: torch.device = device):
  pred_probs = []
  model.to(device)
  model.eval()
  with torch.inference_mode():
    for sample in data:
      # Prepare the sample (add a batch dimension and pass to target device)
      sample = torch.unsqueeze(sample, dim=0).to(device)

      # Forward pass (model outputs raw logits)
      pred_logit = model(sample)

      # Get prediction probability (logit -> prediction probability)
      pred_prob = torch.softmax(pred_logit.squeeze(), dim=0)

      # Get pred_prob off the GPU for further calculations
      pred_probs.append(pred_prob.cpu())

  # Stack the pred_probs to turn list into a tensor
  return torch.stack(pred_probs)

test_samples = []
test_labels = []
i = 0
for sample, label in random.sample(list(test_data), k=9):
  test_samples.append(sample)
  test_labels.append(label)
  i += 1

pred_probs = make_predictions(model=model0,
                              data=test_samples)

pred_classes = pred_probs.argmax(dim=1)
class_names = train_data.classes

plt.figure(figsize=(9, 9))
nrows = 3
ncols = 3
for i, sample in enumerate(test_samples):
  # Create subplot
  plt.subplot(nrows, ncols, i+1)

  # Plot the target image
  plt.imshow(sample.permute(1, 2, 0))

  # Find the prediction (in text form, e.g "Sandal")
  pred_label = class_names[pred_classes[i]]

  # Get the truth label (in text form)
  truth_label = class_names[test_labels[i]]

  # Create a title for the plot
  title_text = f"Pred: {pred_label} | Truth: {truth_label}"

  # Check for equality between pred and truth and change color of title text
  if pred_label == truth_label:
    plt.title(title_text, fontsize=10, c="g") # green text if prediction same as truth
  else:
    plt.title(title_text, fontsize=10, c="r")

  plt.axis(False);

test_samples = []
test_labels = []
i = 0
for sample, label in random.sample(list(test_data), k=9):
  test_samples.append(sample)
  test_labels.append(label)
  i += 1

pred_probs = make_predictions(model=model1,
                              data=test_samples)

pred_classes = pred_probs.argmax(dim=1)
class_names = train_data.classes

plt.figure(figsize=(9, 9))
nrows = 3
ncols = 3
for i, sample in enumerate(test_samples):
  # Create subplot
  plt.subplot(nrows, ncols, i+1)

  # Plot the target image
  plt.imshow(sample.permute(1, 2, 0))

  # Find the prediction (in text form, e.g "Sandal")
  pred_label = class_names[pred_classes[i]]

  # Get the truth label (in text form)
  truth_label = class_names[test_labels[i]]

  # Create a title for the plot
  title_text = f"Pred: {pred_label} | Truth: {truth_label}"

  # Check for equality between pred and truth and change color of title text
  if pred_label == truth_label:
    plt.title(title_text, fontsize=10, c="g") # green text if prediction same as truth
  else:
    plt.title(title_text, fontsize=10, c="r")

  plt.axis(False);

